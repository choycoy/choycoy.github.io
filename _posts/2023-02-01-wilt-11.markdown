---
title: "What I learnt today 01/02/23"
tags:
  - WILT
  - Python
---
ðŸ’¡ This post introduces what I learnt today 01/02/23.
{: .notice--warning}
# Gradient Descent(Advanced)
Using `np.linalog.pinv`, we can find linear regression expression which interprets the data as linear model.
<br>
![gd](https://user-images.githubusercontent.com/40441643/216510956-01f5eb18-ba93-4ddb-ac29-c578cf557ef0.png)
<br>
<br>
**Not using inverse matrix**, find out proper linear model using `gradient descent`.
<br>
![gd2](https://user-images.githubusercontent.com/40441643/216511266-f654deed-1ba2-48b1-af06-ea4d2fdf4873.png)
- find the `coefficient` of linear regression by gradient descent
<br>
![gd3](https://user-images.githubusercontent.com/40441643/216511658-bd1f8ee5-54f8-493c-9fc8-fbc5f0ca8c4f.PNG)
<br>
<br>
It is a complicated calculation, but in fact, only `XT`, which is the result of differentiating `XÎ²` with respect to the `coefficient Î²`, is multiplied.
<br>
<br>
![gd4](https://user-images.githubusercontent.com/40441643/216512991-6798a7e2-dc7a-456c-bfaa-76e215057dd1.png)
<br>
<br>
Now the gradient descent algorithm to find `Î²` which **minimises the objective expression**.
<br>
![gda](https://user-images.githubusercontent.com/40441643/216514385-5e85fc1a-151d-486d-b016-b2e5752eb000.PNG)
<br>
<br>
![gda2](https://user-images.githubusercontent.com/40441643/216514189-9289868a-d1c5-4e34-9292-5b3471093644.PNG)

- Linear Regression Algorithm based on the Gradient Descent

```
Input: X, y, lr, T, Output: beta
norm: function to calculate L2-norm
lr: learning rate, T: number of training

for t in range(T):
    error = y - x @ beta
    grad = - transpose(X) @ error
    beta = beta - lr * grad
```
By calculating `âˆ‡Î²âˆ¥y âˆ’ XÎ²âˆ¥22`, keep updating `Î²`.
<br>
<br>
Therefore, we can calculate regression coefficient using the gradient descent algorithm not inverse matrix.
<br>
<br>
However, in the gradient descent algorithm, the `learning rate` and `number of training` are important parameters.
```
X = np.array([[1,1], [1,2], [2,2], [2,3]])
y = np.dot(X, np.array[1,2]) + 3

beta_gd= [10.1, 15.1, -6.5] # the correct answer is [1, 2, 3]
X_ = np.array([np.append(x,[1]) for x in X]) # add intercept

for t in range(5000):
    error = y - X_ @ beta_gd
    # error = error/ np.linalg.norm(error)
    grad = np.transpose(X_) @ error
    beta_gd = beta_gd - 0.01 * grad

print(beta_gd)

[1.00000367, 1.99999949, 2.999999516]
```
- Do you think that the gradient descent is all-round?
<br>
Theoretically, the gradient descent is differentiable and guaranteed to converge for **convex function** when having proper `learning rate` and `number of training`.
<br>
<br>
In the `convex function`, the gradient vector always goes toward the **minimum point**.
<br>
![convex](https://user-images.githubusercontent.com/40441643/216517669-8a21db05-ec90-4f37-91d6-952fd9159012.png)
<br>
Especially, in case of linear regression, the objective expression `âˆ¥y âˆ’ XÎ²âˆ¥2`is guaranteed to converge if the algorithm is run properly since it is the **convex function** respect to the regression coefficient `Î²`.
<br>
<br>
However, in case of `non-linear regression`, the convergence is not guaranteed because the objective expression can be non-convex.
<br>
<br>
In addition, the objective expression is not convex function when we use Deep Learning.
<br>
![nonconvex](https://user-images.githubusercontent.com/40441643/216518569-3acfd029-2b60-4854-921b-7e18acb7eadc.png)

# Stochastic Gradient Descent(SGD)
`SGD` uses **one data or some of them** to update instead of using all of data.
<br>
**Non-convex objective expression** can be optimised through SGD.
<br>
![sgd](https://user-images.githubusercontent.com/40441643/216518864-66ddc194-b62b-4f92-a0e9-82f677c26ae6.PNG)
<br>
<br>
Since `SGD` updates parameter with some of data, the operation source can be used efficiently.
<br>
![sgd2](https://user-images.githubusercontent.com/40441643/216519243-3b4ade48-1df4-4567-a576-ca9a615fdeb2.png)
<br>
Not using the whole data (X,y), the amount of operation is reduced to `b/n` thanks to using **mini batch(X(b),y(b))** to update.
- `The principle of SGD:` Mini Batch Operation
<br>
The gradient descent calculate the gradient vector `âˆ‡Î¸L(D, Î¸)` of the objective expression with the `whole data D = (X, y)`.
<br>
<br>
`âˆ‡Î¸L(D, Î¸)` is the objective expression to measure the whole data `D` and parameter `Î¸`.
<br>
![gd5](https://user-images.githubusercontent.com/40441643/216521734-2cf49a41-461b-46bd-922b-8cdcd1391401.png)
<br>
<br>
`SGD` calculates the gradient vector with `mini batch D(b) = (X(b), y(b)) âŠ‚ D`.
<br>
![sgd3](https://user-images.githubusercontent.com/40441643/216522519-d9ab90a6-3ccf-4b48-b321-d8fdfd529464.png)
<br>
<br>
As Mini batch is selected statistically, the shape of objective expression is changed.
<br>
![sgd4](https://user-images.githubusercontent.com/40441643/216522840-5f9f68b4-8494-4c9d-978e-3c0393d36fb6.png)
<br>
Since mini batch is changed every time, the curve shape is changed as well.
<br>
<br>
`SGD` is more **efficient** than the descent gradient algorithm in machine learning because `SGD` is possible to use the objective expression which is **non convex**.
<br>
![sgd5](https://user-images.githubusercontent.com/40441643/216524052-086f79bb-a17e-456d-a10d-5957fd2b3e73.png)

- In hardware
![gd6](https://user-images.githubusercontent.com/40441643/216524380-4e383016-999f-49b9-b3ef-04cce6c3ad83.png)
<br>
If we upload the whole data as the general gradient descent method, `out of memory` can be happened.
<br>
<br>
![sgd_final](https://user-images.githubusercontent.com/40441643/216524857-19f3762f-5170-4ffc-9866-4b0ec0446259.png)

# Probability Theory
Deep Learning is based on the theory of machine learning on probability theory.
<br>
The operating principle of `loss functions` used in machine learning is derived by **statistically interpreting the data space**.
<br>
<br>
The principle of learning data to `minimise the risk` of incorrect predictions is a fundamental principle of statistical machine learning.
<br>
<br>
In the regression analysis, L2-norm used as the loss function derives learning to **minimise the distribution of prediction error**.
<br>
<br>
The `cross-entropy` used in the classification problem derives learning to **minimise an unpredictability** of model prediction.
<br>
We need to know the method to minimise the distribution or unpredictability. Since the methods to measure two objects are provided in the statistics, we need to know the basic concept of probability theory to understand the machine learning.
<br>
- The probability distribution is a portrait of data
<br>
The `data space` is denoted by `X x Y` and `D` is the distribution to extract the data in the data space.
<br>
![data_space](https://user-images.githubusercontent.com/40441643/216568075-68e527e8-c4ae-4f53-a00b-f2b7f07f9993.PNG)
<br>
Data is denoted by (x,y)~D as the statistical variable.
<br>
(x,y)âˆˆ X Ã— Y is an observable data in the data space.

- `Discrete Random variable` vs `Continuous Random Variable`
<br>
Random Variable is distinguished by the `discrete random variable` and `continuous random variable` according to the probability distribution `D`.
<br>
<br>
 A `Discrete Random Variable` is modelled by adding the probability by **considering all the possible cases** of the random variable.
