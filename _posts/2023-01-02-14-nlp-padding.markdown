---
title: "14 NLP: Padding"
tags:
  - NLP
  - Keras' pad_sequences
  - Zero Padding
  - Padding
---
ðŸ’¡ This post introduces padding with Numpy and Keras' pad_sequences.
{: .notice--warning}

In `nlp`, each sentence (or document) can be different of lengths. However, the machine cane see all documents of the **same length** as one `matrix` and process them **all at once**. In other words, there are times when it is necessary to **arbitrarily match the length of several sentences** for parallel operation. Let's understand through practice.

## 1. Padding With Numpy
```
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
```

Let's repeat the exercise we did in the integer encoding chapter, I have text data as below.
```
preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]
```

Creates `a set of words` and performs `integer encoding`

```
tokenizer = Tokenizer()
tokenizer.fit_on_texts(preprocessed_sentences)
encoded = tokenizer.texts_to_sequences(preprocessed_sentences)
print(encoded)
```

All words have been converted to unique integers.
```
[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]
```

To make them **all the same length**, let's calculate `the length of the longest sentence` among them.
```
max_len = max(len(item) for item in encoded)
print('the max of length:', max_len)
```

```
the max of length: 7
```

The length of the longest sentence is `7`. Let's set the length of all sentences to `7`. In this case, **the fictional word** `PAD` is used. Suppose we have the word `PAD`, and we define it as `word number 0`. Sentences **shorter than 7** are `padded` with `zeros` to make them `7`.
```
for sentence in encoded:
    while len(sentence) < max_len:
          sentence.append(0)

padded_np = np.array(encoded)
padded_np
```

```
array([[ 1,  5,  0,  0,  0,  0,  0],
       [ 1,  8,  5,  0,  0,  0,  0],
       [ 1,  3,  5,  0,  0,  0,  0],
       [ 9,  2,  0,  0,  0,  0,  0],
       [ 2,  4,  3,  2,  0,  0,  0],
       [ 3,  2,  0,  0,  0,  0,  0],
       [ 1,  4,  6,  0,  0,  0,  0],
       [ 1,  4,  6,  0,  0,  0,  0],
       [ 1,  4,  2,  0,  0,  0,  0],
       [ 7,  7,  3,  2, 10,  1, 11],
       [ 1, 12,  3, 13,  0,  0,  0]])
```

You can see that all sentences with a `length of less than 7` are **appended with the number 0**, so that all sentences are 7 in length. The machine see them as a `single matrix` and can process them in parallel. Also, since `word 0` is actually meaningless, the machine will **ignore word 0** during `nlp`. Adjusting the shape of data **by filling it with specific value** like this is called `padding`. If you're using the `number 0`, it is called `zero padding`.


## 2. Padding with the Keras preprocessor
`Keras` provides `pad_sequences()` for `padding` like above.
```
from tensorflow.keras.preprocessing.sequence import pad_sequences
```

Since the encoded values has already been saved as the result after `padding` above, let's return it to the value before `padding`.
```
encoded = tokenizer.texts_to_sequences(preprocessed_sentences)
print(encoded)
```

```
[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]
```

Let's try `padding` using `Keras' pad_sequences`.
```
padded = pad_sequences(encoded)
padded
```

```
array([[ 0,  0,  0,  0,  0,  1,  5],
       [ 0,  0,  0,  0,  1,  8,  5],
       [ 0,  0,  0,  0,  1,  3,  5],
       [ 0,  0,  0,  0,  0,  9,  2],
       [ 0,  0,  0,  2,  4,  3,  2],
       [ 0,  0,  0,  0,  0,  3,  2],
       [ 0,  0,  0,  0,  1,  4,  6],
       [ 0,  0,  0,  0,  1,  4,  6],
       [ 0,  0,  0,  0,  1,  4,  2],
       [ 7,  7,  3,  2, 10,  1, 11],
       [ 0,  0,  0,  1, 12,  3, 13]], dtype=int32)
```

The padding result is different from when padding is done with `Numpy` because `pad_sequences` basically **fills the document with zeros at the beginning**, not at the end, If you want to pad the back with `0`, you can give `padding = 'post'` as an argument.
```
padded = pad_sequences(encoded, padding = 'post')
padded
```

```
array([[ 1,  5,  0,  0,  0,  0,  0],
       [ 1,  8,  5,  0,  0,  0,  0],
       [ 1,  3,  5,  0,  0,  0,  0],
       [ 9,  2,  0,  0,  0,  0,  0],
       [ 2,  4,  3,  2,  0,  0,  0],
       [ 3,  2,  0,  0,  0,  0,  0],
       [ 1,  4,  6,  0,  0,  0,  0],
       [ 1,  4,  6,  0,  0,  0,  0],
       [ 1,  4,  2,  0,  0,  0,  0],
       [ 7,  7,  3,  2, 10,  1, 11],
       [ 1, 12,  3, 13,  0,  0,  0]], dtype=int32)
```

The result is the same as when padding using `Numpy`. Compares two results to see if they are **actually identical**.
```
(padded == padded_np).all()
```

```
True
```

A `true` value is returned. It means both results are the same. So far we've assumed `padding` based on the **length of the document with the longest length**, but in practice it does not have to be based on the length of the longest document. For example, if the `average length` of all documents is `20` and one document is `5,000` long, it may not be necessary to pad all documents to 5,000. In cases like this, you can **limit the length** and pad it. If an integer is given as the `argument of maxlen`, the **length of all documents** is equal to `that integer`.
```
padded = pad_sequences(encoded, padding = 'post', maxlen = 5)
padded
```

```
array([[ 1,  5,  0,  0,  0],
       [ 1,  8,  5,  0,  0],
       [ 1,  3,  5,  0,  0],
       [ 9,  2,  0,  0,  0],
       [ 2,  4,  3,  2,  0],
       [ 3,  2,  0,  0,  0],
       [ 1,  4,  6,  0,  0],
       [ 1,  4,  6,  0,  0],
       [ 1,  4,  2,  0,  0],
       [ 3,  2, 10,  1, 11],
       [ 1, 12,  3, 13,  0]], dtype=int32)
  ```

Document shorter than `5` will be padded with `0s`, and data will be lost if they were previously longer than `5`. For example, the second sentence from the back was originally `[ 7, 7, 3, 2, 10, 1, 11]`, but now you can see that it has been changed to `[3, 2, 10, 1, 11]`. If you want to **delete the next word** rather than the **previous word** in case of `data loss`, use the `truncating argument`. If you use `truncating ='post'`, the word after it is deleted.
```
padded = pad_sequences(encoded, padding = 'post', truncating ='post', maxlen = 5)
padded
```

```
array([[ 1,  5,  0,  0,  0],
       [ 1,  8,  5,  0,  0],
       [ 1,  3,  5,  0,  0],
       [ 9,  2,  0,  0,  0],
       [ 2,  4,  3,  2,  0],
       [ 3,  2,  0,  0,  0],
       [ 1,  4,  6,  0,  0],
       [ 1,  4,  6,  0,  0],
       [ 1,  4,  2,  0,  0],
       [ 7,  7,  3,  2, 10],
       [ 1, 12,  3, 13,  0]], dtype=int32)
```

Although padding with `zeros` is a widespread practice, it is not a mandatory rule. If you want to use a number other than `0` for `padding`, this is also possible. Let's use `+1` as a number for the **size of the word set**, so that it does not overlap with the integers currently used.
```
last_value = len(tokenizer.word_index) + 1
print(last_value)
```

```
14
```

Since there are currently `13 words` in total, and integers `1 through 13 are used`, **adding 1 to the size of the word** gives `14`, which is 1 more than the last number. `pad_sequences` can be padded with a number other than `0` by using as an `argument`.
```
padded = pad_sequences(encoded, padding ='post', value = last_value)
padded
```

```
array([[ 1,  5, 14, 14, 14, 14, 14],
       [ 1,  8,  5, 14, 14, 14, 14],
       [ 1,  3,  5, 14, 14, 14, 14],
       [ 9,  2, 14, 14, 14, 14, 14],
       [ 2,  4,  3,  2, 14, 14, 14],
       [ 3,  2, 14, 14, 14, 14, 14],
       [ 1,  4,  6, 14, 14, 14, 14],
       [ 1,  4,  6, 14, 14, 14, 14],
       [ 1,  4,  2, 14, 14, 14, 14],
       [ 7,  7,  3,  2, 10,  1, 11],
       [ 1, 12,  3, 13, 14, 14, 14]], dtype=int32)
```
